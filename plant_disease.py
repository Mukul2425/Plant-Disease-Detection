# -*- coding: utf-8 -*-
"""Plant_Disease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aBMnERAs19LClxmI72Db-BHlmUl3bBJQ
"""

import kagglehub

DATASET_PATH = kagglehub.dataset_download(
    "vipoooool/new-plant-diseases-dataset"
)

print(DATASET_PATH)

import os

print("Dataset root path:")
print(DATASET_PATH)

print("\nContents of dataset root:")
print(os.listdir(DATASET_PATH))

for item in os.listdir(DATASET_PATH):
    print(item)

DATA_ROOT = os.path.join(
    DATASET_PATH,
    "New Plant Diseases Dataset(Augmented)",
    "New Plant Diseases Dataset(Augmented)"
)

print(os.listdir(DATA_ROOT))

TRAIN_DIR = os.path.join(DATA_ROOT, "train")
VAL_DIR   = os.path.join(DATA_ROOT, "valid")

print("Train dir:", TRAIN_DIR)
print("Val dir:", VAL_DIR)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMG_SIZE = (224, 224)
BATCH_SIZE = 32

train_datagen = ImageDataGenerator(rescale=1./255)
val_datagen   = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical"
)

val_generator = val_datagen.flow_from_directory(
    VAL_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical"
)

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

base_model = MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights="imagenet"
)

base_model.trainable = False  # Freeze base layers

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(256, activation="relu")(x)
x = Dropout(0.5)(x)

predictions = Dense(
    train_generator.num_classes,
    activation="softmax"
)(x)

model = Model(inputs=base_model.input, outputs=predictions)

model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss="categorical_crossentropy",
    metrics=["accuracy"]
)
model.summary()

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=5
)

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
plt.plot(history.history["accuracy"], label="Train Accuracy")
plt.plot(history.history["val_accuracy"], label="Val Accuracy")
plt.legend()
plt.title("Training vs Validation Accuracy")
plt.show()

model.save("plant_disease_model.h5")

import json

class_mapping = train_generator.class_indices

with open("class_mapping.json", "w") as f:
    json.dump(class_mapping, f)

from google.colab import files

files.download("plant_disease_model.h5")
files.download("class_mapping.json")

val_loss, val_accuracy = model.evaluate(val_generator)
print(f"Validation Loss: {val_loss:.4f}")
print(f"Validation Accuracy: {val_accuracy:.4f}")

val_generator_eval = val_datagen.flow_from_directory(
    VAL_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="categorical",
    shuffle=False   # ðŸ”¥ CRITICAL
)

import numpy as np

y_pred_probs = model.predict(val_generator_eval)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = val_generator_eval.classes

from sklearn.metrics import classification_report

class_names = list(val_generator_eval.class_indices.keys())

print(classification_report(
    y_true,
    y_pred,
    target_names=class_names
))

import tensorflow as tf

top_3 = tf.keras.metrics.top_k_categorical_accuracy(
    tf.keras.utils.to_categorical(y_true, num_classes=len(class_names)),
    y_pred_probs,
    k=3
)

print("Top-3 Accuracy:", float(np.mean(top_3)))

